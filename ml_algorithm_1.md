# ML_Algorithm

## 알고리즘 종류 

![개요](https://miro.medium.com/max/2000/1*8wU0hfUY3UK_D8Y7tbIyFQ.png)

알고리즘을 다양한 기준으로 구분 가능하다.(상호 배타적이지 않다.)
  1. 훈련 지도 여부 : 지도 학습, 비지도 학습, 준지도 학습, 강화 학습
  2. 실시간 훈련 여부 : 온라인 학습, 배치 학습
  3. 예측 모델 사용 여부 : 사례 기반 학습, 모델 기반 학습

    Ex 스팸 메일 구분 CASE : 지도 학습, 온라인 학습, 모델 기반 학습

  ## 훈련 방법에 따른 구분

  ### [지도 학습(Supervised Learning)](./Supervised_Learning.md)
  **훈련 데이터로부터 하나의 함수를 유추하기 위한 방법.** 훈련데이터에 **Label** 이라는 원하는 답이 포함되어야 한다.훈련 데이터를 학습하여 함수를 유추하고, 훈련 데이터마다 기댓값(input 기준 expect output)을 생성, Label을 통해 정답여부를 판단(feedback)하여 함수를 조정해나간다.
대표적인 지도학습의 종류로는 유추된 함수 중 연속적인 값을 출력하는 **회귀(Regression)**, 입력 데이터가 어떤 종류의 값인지 표시,구분하는 **분류(Classification)** 가 있다.

  ### 비지도 학습(Unsupervised Learning)
  비지도 학습은 **Label이 없는 훈련 데이터를 이용하여 시스템 스스로 학습**을 하도록 하는 학습 방법.데이터가 어떻게 구성되어 있는 지를 알아내는 문제의 범주에 속한다. 지도,준지도,강화 학습과 달리 입력값에 대한 목표치가 주어지지 않는다. 따라서 Label이 필요하지 않다.
  ### 준지도 학습(Semisupervised Learning)
  Label이 적용된 **적은 수의 샘플** 이 주어졌을 때 유용한 방법.비지도 학습을 통해 군집을 분류한 후 샘플을 활용하여 지도 학습을 실행하는 것 대부분 머신러닝에서 지도 학습과 비지도 학습을 혼합하여 수행한다.
  예 : Google 포토 호스팅 : 가족사진 몇장에 Label 등록하여 이후 사진에서 가족사진 확인 가능.

  ### 강화 학습(Reinforcement Learning)
학습 시스템을 **에이전트(Agent)** 라 부르며,에이전트는 **환경(Environment)을 관찰하여 행동(Action)을 실행하고,이에 따라 보상(Reward)을 주어 가장 큰 보상을 받는 최상의 전략(Policy)을 스스로 학습**하는 것.
정책은 주어진 상황에서 에이전트가 어떻게 행동해야하는지 판단한다.
예 : 알파고
